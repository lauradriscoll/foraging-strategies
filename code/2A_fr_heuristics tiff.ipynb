{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb07218d-915d-4165-b8ff-c12852149418",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "# Add the directory containing the library to sys.path\n",
    "import os\n",
    "import sys\n",
    "library_path = os.path.abspath(r'C:\\git\\foraging-strategies\\code')\n",
    "if library_path not in sys.path:\n",
    "    sys.path.append(library_path)\n",
    "    \n",
    "from tools_fixed import PatchForager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a138eb4",
   "metadata": {},
   "source": [
    "### **Grid search for best parameters of any given strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e05236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grid search for best parameters\n",
    "# Create a directory for the simulation results\n",
    "\n",
    "\n",
    "df_sum = pd.DataFrame(columns=['x', 'y', 'reward_rate'])\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Parameters of reward in each patch for fixed rew\n",
    "travel_time = 3\n",
    "reward_value = [5, 5]\n",
    "num_rew = [1,5]\n",
    "first_rew = [0,2]\n",
    "last_rew = [num_rew[0],num_rew[1]] #this needs to be a fxn of rew or stops, careful setting values\n",
    "reward_prob = [0.9, 0.9]\n",
    "indep_var = 'rewards'\n",
    "type_patches = len(num_rew)\n",
    "num_patches = 1000\n",
    "patch_list = [random.randint(0, type_patches-1) for _ in range(num_patches)] #randomly generated list of patched\n",
    "\n",
    "# Create the reward prob matrix\n",
    "a = np.zeros((type_patches, max(last_rew)+1), dtype=float)\n",
    "b = np.zeros((type_patches, 1), dtype=float)\n",
    "c = np.zeros((type_patches, 1), dtype=float)\n",
    "\n",
    "# Set depletion curves\n",
    "for patch_id in range(type_patches):\n",
    "    a[patch_id, :num_rew[patch_id]] = reward_prob[patch_id] # fixed prob for each patch TODO make more flexible\n",
    "    b[patch_id] = first_rew[patch_id]\n",
    "    c[patch_id] = last_rew[patch_id]\n",
    "\n",
    "d = '_'\n",
    "\n",
    "forager = PatchForager(travel_time, reward_value, a, b, c, d, prob=True, depl_fxn = 'fixed', indep_var = indep_var)\n",
    "\n",
    "# mvt_optimal = forager.calculate_optimal_stops(patch_list)\n",
    "# print('Max reward rate:', mvt_optimal['max_reward_rate'])\n",
    "# print('Stops', mvt_optimal['optimal_stops'])\n",
    "\n",
    "# Create an HDF5 file\n",
    "with h5py.File('data/data.h5', 'w') as hf:\n",
    "    for x in range(0, 20):\n",
    "        for y in range (0,20):\n",
    "            \n",
    "            strategy_info = {'strategy': 'stops', 'params': {'target_stops': [x, y]}}\n",
    "            # strategy_info = {'strategy': 'rewards', 'params': {'target_rewards': [x, y]}}\n",
    "            # strategy_info = {'strategy': 'failures', 'params': {'max_failures': [x, y]}}\n",
    "            # strategy_info = {'strategy': 'consec_failures', 'params': {'consec_failures': [x, y]}}\n",
    "\n",
    "            # Run the simulation for each strategy\n",
    "            data, _ = forager.run_simulation(strategy_info['strategy'], patch_list, **strategy_info['params'])\n",
    "            \n",
    "            df_sum.loc[len(df_sum)] = [x, y, _] \n",
    "\n",
    "# Pivot the DataFrame to create a matrix\n",
    "heatmap_data = df_sum.pivot(index = 'y', columns = 'x', values =  'reward_rate')\n",
    "\n",
    "max_value = heatmap_data.max().max()\n",
    "max_cell = heatmap_data.stack().idxmax()\n",
    "print(f\"The cell with the largest value is at {max_cell} \\n with a value of {max_value}\")\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(heatmap_data, cmap='magma')\n",
    "plt.title('Reward Rate for ' + strategy_info['strategy'])\n",
    "plt.xlabel('Patch 1 values')\n",
    "plt.ylabel('Patch 2 values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d8c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame to create a matrix\n",
    "heatmap_data = df_sum.pivot(index = 'y', columns = 'x', values =  'reward_rate')\n",
    "\n",
    "max_value = heatmap_data.max().max()\n",
    "max_cell = heatmap_data.stack().idxmax()\n",
    "print(f\"The cell with the largest value is at {max_cell} \\n with a value of {max_value}\")\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(heatmap_data, cmap='magma')\n",
    "plt.title('Reward Rate for ' + strategy_info['strategy'])\n",
    "plt.xlabel('Patch 1 values')\n",
    "plt.ylabel('Patch 2 values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb9592b",
   "metadata": {},
   "source": [
    "### **Simulation of different strategies and comparison of reward rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad97affa-3bae-49dd-beee-4fe47b28760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum = pd.DataFrame(columns=['simulation', 'strategy', 'reward_rate'])\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Parameters of reward in each patch for fixed rew\n",
    "travel_time = 3\n",
    "reward_value = [5, 5, 5]\n",
    "num_rew = [1,5,0]\n",
    "first_rew = [0,2,0]\n",
    "last_rew = [num_rew[0],num_rew[1],0] #this needs to be a fxn of rew or stops, careful setting values\n",
    "reward_prob = [.9,.9,0]\n",
    "indep_var = 'stops'\n",
    "type_patches = len(num_rew)\n",
    "num_patches = 200\n",
    "patch_list = [random.randint(0, type_patches-1) for _ in range(num_patches)] #randomly generated list of patched\n",
    "\n",
    "# Create the reward prob matrix\n",
    "a = np.zeros((type_patches, max(last_rew)+1), dtype=float)\n",
    "b = np.zeros((type_patches, 1), dtype=float)\n",
    "c = np.zeros((type_patches, 1), dtype=float)\n",
    "\n",
    "# Set depletion curves\n",
    "for patch_id in range(type_patches):\n",
    "    a[patch_id, :num_rew[patch_id]] = reward_prob[patch_id] # fixed prob for each patch TODO make more flexible\n",
    "    b[patch_id] = first_rew[patch_id]\n",
    "    c[patch_id] = last_rew[patch_id]\n",
    "\n",
    "d = '_'\n",
    "\n",
    "forager = PatchForager(travel_time, reward_value, a, b, c, d, prob=True, depl_fxn = 'fixed', indep_var = indep_var)\n",
    "# mvt_optimal = forager.calculate_optimal_stops(patch_list)\n",
    "# print('Max reward rate:', mvt_optimal['max_reward_rate'])\n",
    "# print('Stops', mvt_optimal['optimal_stops'])\n",
    "\n",
    "# Define the strategies and their parameters\n",
    "strategy_struct = {\n",
    "    # 'rewards_opt': {'strategy': 'rewards', 'params': {'target_rewards': [1,2,0]}}, #this seems to run forever sometimes, maybe never leaves?\n",
    "    # 'patch_type': {'strategy': 'patch_type', 'params': {'target_patches': [{'target_rewards': 3},\n",
    "    #                                                                         {'target_stops': 6},\n",
    "    #                                                                         {'target_stops': 0}]}},\n",
    "    'stops_opt': {'strategy': 'stops', 'params': {'target_stops': [1,5,0]}},\n",
    "    'failures_opt': {'strategy': 'failures', 'params': {'max_failures': [0,3,0]}},\n",
    "    'consec_failures_opt': {'strategy': 'consec_failures', 'params': {'consec_failures': [1,3,0]}},\n",
    "}\n",
    "\n",
    "# Create an HDF5 file\n",
    "with h5py.File('data/data.h5', 'w') as hf:\n",
    "    for i in range(50):\n",
    "        # Create a group for this simulation\n",
    "        sim_group = hf.create_group(f'simulation_{i}')\n",
    "        \n",
    "        # Run the simulation for each strategy\n",
    "        for strategy_name, strategy_info in strategy_struct.items():\n",
    "            data, _ = forager.run_simulation(strategy_info['strategy'], patch_list, **strategy_info['params'])\n",
    "            \n",
    "            df_sum.loc[len(df_sum)] = [i, strategy_name, _] \n",
    "                       \n",
    "            # Save results\n",
    "            data = data.replace({None: np.nan})\n",
    "            dataset = sim_group.create_dataset(strategy_name, data=data.to_numpy())\n",
    "            # Save column names as attributes\n",
    "            dataset.attrs['columns'] = data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_cum=pd.DataFrame()\n",
    "# value = df_sum.loc[df_sum['strategy'] == 'stops_opt'].reward_rate.mean()\n",
    "# df_sum['reward_rate'] = df_sum['reward_rate'] - value\n",
    "# df_sum['travel_time'] = travel_time\n",
    "# df_sum['patches'] = indep_var+'_'+str(num_rew[0])+'_'+str(num_rew[1])\n",
    "# # df_cum = pd.concat([df_sum, df_cum])\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(6, 4))\n",
    "# sns.boxplot(x ='strategy', y='reward_rate', data=df_sum, hue='patches')\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef09f27-e1d7-47fb-9cb4-f43787d88741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read data from HDF5 file\n",
    "def read_h5_data(file_path, simulation_number, strategy):\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        dataset = hf[f'simulation_{simulation_number}/{strategy}']\n",
    "        return pd.DataFrame(dataset[:], columns=dataset.attrs['columns'])\n",
    "\n",
    "# Set up the plotting style\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# File path\n",
    "h5_file_path = 'data/data.h5'\n",
    "\n",
    "# Get a list of distinct colors from matplotlib colormap\n",
    "colors = plt.get_cmap('tab10')  # You can change 'tab10' to other colormaps if needed\n",
    "\n",
    "# Create the color_set dictionary\n",
    "color_set = {strategy: colors(i) for i, strategy in enumerate(strategy_struct.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb29b4-40ca-4303-b95e-8bdcfcd9ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "for sim_num in range(20):  # Assuming 20 simulations\n",
    "\n",
    "    for strategy in strategy_struct.keys():\n",
    "        # Read data for this simulation and strategy\n",
    "        data = read_h5_data(h5_file_path, sim_num, strategy)\n",
    "        \n",
    "        # Plot cumulative reward over time\n",
    "        plt.plot(data['time'], data['reward'].cumsum(), label=strategy.replace('_', ' ').title(),alpha = .3,\n",
    "                 lw = 1,color = color_set[strategy])\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Cumulative Reward')\n",
    "    plt.title(f'Cumulative Reward over Time \\n for Different Strategies \\n Travel Time: {travel_time}s')\n",
    "    \n",
    "    if sim_num==0:\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "# plt.savefig(f'figs/cumulative_reward_all.png', bbox_inches='tight', dpi=300)\n",
    "# plt.close()  # Close the figure to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8a967-5b80-44b8-919f-f28fc4cf2f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of simulations\n",
    "num_simulations = 20\n",
    "\n",
    "# Plot: Reward Rate over Time\n",
    "plt.figure(figsize=(6, 4))\n",
    "for sim_num in range(num_simulations):\n",
    "    for strategy in strategy_struct.keys():\n",
    "        # Read data for this simulation and strategy\n",
    "        data = read_h5_data(h5_file_path, sim_num, strategy)\n",
    "        \n",
    "        # Calculate reward rate\n",
    "        cumulative_reward = data['reward'].cumsum()\n",
    "        reward_rate = cumulative_reward / data['time']\n",
    "        \n",
    "        # Plot reward rate over time\n",
    "        plt.plot(data['time'], reward_rate, label=strategy.replace('_', ' ').title() if sim_num == 0 else \"\", \n",
    "                 alpha=0.3, color=color_set[strategy], linewidth = 1)\n",
    "    if sim_num == 0:\n",
    "        plt.legend()\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Reward Rate')\n",
    "plt.title('Reward Rate over Time for Different Strategies')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "# plt.savefig('figs/reward_rate_all.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dc2dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of simulations\n",
    "num_simulations = 20\n",
    "\n",
    "# Plot: Time Spent in Each Patch\n",
    "fig, axs = plt.subplots(1,4, figsize=(12, 4), sharey=True)\n",
    "\n",
    "for variable, ax_flat in zip(['time_in_patch', 'rewards_in_patch', 'failures_in_patch', 'consecutive_failures'], axs.flatten()):\n",
    "    ax = ax_flat\n",
    "    for sim_num in range(num_simulations):\n",
    "        for strategy in strategy_struct.keys():\n",
    "            \n",
    "            # Read data for this simulation and strategy\n",
    "            data = read_h5_data(h5_file_path, sim_num, strategy)\n",
    "            \n",
    "            # Calculate time spent in each patch\n",
    "            # if variable == 'time_in_patch':\n",
    "            #     patch_times = data[data['patch_id'] != -1].groupby('patch_id')[variable].max()\n",
    "            # else:\n",
    "            #     patch_times = data[data['patch_id'] != -1].groupby('patch_id')[variable].mean()\n",
    "            \n",
    "            df_results = data[data['patch_id'] != -1].groupby(['patch_id', 'patch_entry_time'])[variable].max().reset_index()\n",
    "            patch_times = df_results.groupby(['patch_id'])[variable].mean()            \n",
    "            # Plot time spent in each patch\n",
    "            ax.plot(patch_times.index, patch_times.values, label=strategy if sim_num == 0 else \"\", \n",
    "                    marker='o', alpha=0.3, color=color_set[strategy])\n",
    "\n",
    "            ax.set_xlabel('Patch ID')\n",
    "            ax.set_xlim([-.9,2.9])\n",
    "            ax.set_title(variable)\n",
    "# plt.ylabel('Time Spent in Patch')\n",
    "# plt.title('Time Spent in Each Patch \\n for Different Strategies')\n",
    "if sim_num == 0:\n",
    "    plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.legend(strategy_struct.keys(), bbox_to_anchor=(2.05,1), loc='upper right')\n",
    "\n",
    "# plt.savefig(f'figs/patch_stops.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "sns.scatterplot(x ='strategy', y='reward_rate', data=df_sum, hue='strategy', palette='tab10')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663464a2",
   "metadata": {},
   "source": [
    "### **Simulate and explore within session statistics for different strategies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionData:\n",
    "    def __init__(self, simulated_data):\n",
    "        self.df = simulated_data\n",
    "        self.variables = ['time_in_patch', 'prob_reward', 'cumulative_patch_reward', 'failures_in_patch', 'consecutive_failures']\n",
    "    \n",
    "    def process_last_timesteps(self):\n",
    "        # Group by patch visit and get the last row of each visit\n",
    "        grouped = self.df[self.df['patch_id'] != -1].groupby((self.df['patch_id'] != self.df['patch_id'].shift()).cumsum())\n",
    "        last_timesteps = grouped.last().reset_index(drop=True)\n",
    "        return last_timesteps\n",
    "    \n",
    "    def plot_variables_by_patch(self):\n",
    "        last_timesteps = self.process_last_timesteps()\n",
    "        \n",
    "        # Create a color map for patches\n",
    "        unique_patches = last_timesteps['patch_id'].unique()\n",
    "        color_map = plt.get_cmap('tab20')\n",
    "        color_dict = {patch: color_map(i/len(unique_patches)) for i, patch in enumerate(unique_patches)}\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(14, 8), sharex=True)\n",
    "        fig.suptitle('Variables at Patch Exit, Colored by Patch', fontsize=16)\n",
    "        \n",
    "        for var, ax1 in zip(self.variables, axes.flatten()):\n",
    "            ax = ax1\n",
    "            for patch in unique_patches:\n",
    "                patch_data = last_timesteps[last_timesteps['patch_id'] == patch]\n",
    "                ax.scatter(patch_data.index, patch_data[var], \n",
    "                           c=[color_dict[patch]], label=f'Patch {patch}', s=10)\n",
    "            \n",
    "            ax.set_ylabel(var.replace('_', ' ').title())\n",
    "            ax.grid(True, linestyle='--', alpha=0.3)\n",
    "            ax.legend()\n",
    "        \n",
    "        ax.set_xlabel('Patch Visit Number')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_overall_reward_rate(self):\n",
    "        # Calculate cumulative sum of rewards\n",
    "        cumulative_rewards = self.df['reward'].cumsum()\n",
    "        \n",
    "        # Use the 'time' column for total time\n",
    "        total_time = self.df['time']\n",
    "        \n",
    "        # Calculate reward rate\n",
    "        reward_rate = cumulative_rewards / total_time\n",
    "        \n",
    "        plt.figure(figsize=(3, 2))\n",
    "        plt.plot(total_time, reward_rate)\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Overall Reward Rate')\n",
    "        # plt.title('Overall Reward Rate Throughout the Session')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c43a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation for each strategy\n",
    "results = {}\n",
    "for strategy_name, strategy_info in strategy_struct.items():\n",
    "    simulated_data, _ = forager.run_simulation(strategy_info['strategy'], patch_list, **strategy_info['params'])\n",
    "    results[strategy_name] = data\n",
    "\n",
    "    print(strategy_name)\n",
    "    session = SessionData(simulated_data)\n",
    "    session.plot_variables_by_patch()\n",
    "    # session.plot_overall_reward_rate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
